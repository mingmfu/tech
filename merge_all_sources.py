#!/usr/bin/env python3
"""
TechInsight Hub - å…¨ä¿¡æ¯æºæ•´åˆåˆ†æ
åˆå¹¶ï¼šçŸ¥ä¹ã€å¾®åšã€ç™¾åº¦ã€Hacker News + è´¢è”ç¤¾ã€è´´å§
"""

import json
from datetime import datetime
from pathlib import Path

def load_all_data():
    """åŠ è½½æ‰€æœ‰æ•°æ®æº"""
    # åŠ è½½åŸºç¡€æ•°æ®ï¼ˆå·²å­˜åœ¨çš„ï¼‰
    with open('api/trending_raw.json', 'r', encoding='utf-8') as f:
        base_data = json.load(f)
    
    # åŠ è½½æ‰©å±•æ•°æ®
    try:
        with open('api/extended_sources.json', 'r', encoding='utf-8') as f:
            extended_data = json.load(f)
    except:
        extended_data = {'cailianshe': [], 'tieba': [], 'rss': []}
    
    return base_data, extended_data

def merge_and_analyze(base_data, extended_data):
    """åˆå¹¶æ‰€æœ‰æ•°æ®å¹¶åˆ†æ"""
    all_items = []
    
    # åŸºç¡€æ•°æ®æº
    source_names = {
        'zhihu': 'çŸ¥ä¹',
        'weibo': 'å¾®åš', 
        'baidu': 'ç™¾åº¦',
        'hackernews': 'Hacker News'
    }
    
    for platform, items in base_data.items():
        if isinstance(items, list) and platform in source_names:
            for item in items:
                item['source_group'] = 'åŸºç¡€æº'
                item['source_type'] = source_names[platform]
                all_items.append(item)
    
    # æ‰©å±•æ•°æ®æº
    ext_source_names = {
        'cailianshe': 'è´¢è”ç¤¾',
        'tieba': 'è´´å§',
        'rss': 'RSSè®¢é˜…'
    }
    
    for platform, items in extended_data.items():
        if isinstance(items, list) and platform in ext_source_names:
            for item in items:
                item['source_group'] = 'æ‰©å±•æº'
                item['source_type'] = ext_source_names[platform]
                all_items.append(item)
    
    return all_items

def generate_full_insight(all_items):
    """ç”Ÿæˆå…¨ä¿¡æ¯æºçƒ­ç‚¹è§£è¯»"""
    
    # æŒ‰å¹³å°åˆ†ç»„
    by_platform = {}
    for item in all_items:
        platform = item.get('platform', 'unknown')
        if platform not in by_platform:
            by_platform[platform] = []
        by_platform[platform].append(item)
    
    lines = []
    lines.append("## ğŸ“Š ä»Šæ—¥AIçƒ­ç‚¹å…¨æ™¯åˆ†æ\n")
    
    # æ•°æ®æ¦‚è§ˆ
    base_count = len([i for i in all_items if i.get('source_group') == 'åŸºç¡€æº'])
    ext_count = len([i for i in all_items if i.get('source_group') == 'æ‰©å±•æº'])
    lines.append(f"**æ•°æ®æ¦‚è§ˆ**ï¼šæ•´åˆ {len(all_items)} æ¡çƒ­ç‚¹æ•°æ®")
    lines.append(f"- åŸºç¡€æºï¼ˆçŸ¥ä¹/å¾®åš/ç™¾åº¦/HNï¼‰ï¼š{base_count} æ¡")
    lines.append(f"- æ‰©å±•æºï¼ˆè´¢è”ç¤¾/è´´å§ï¼‰ï¼š{ext_count} æ¡\n")
    
    # å„å¹³å°ç„¦ç‚¹
    lines.append("**å„å¹³å°çƒ­ç‚¹èšç„¦**ï¼š\n")
    
    if 'zhihu' in by_platform:
        items = by_platform['zhihu'][:2]
        lines.append(f"ğŸ“š **çŸ¥ä¹**ï¼ˆæŠ€æœ¯æ·±åº¦ï¼‰ï¼š")
        for item in items:
            lines.append(f"  â€¢ {item['title'][:35]}...")
    
    if 'weibo' in by_platform:
        items = by_platform['weibo'][:2]
        lines.append(f"\nğŸ“± **å¾®åš**ï¼ˆå¤§ä¼—ä¼ æ’­ï¼‰ï¼š")
        for item in items:
            lines.append(f"  â€¢ {item['title'][:30]}...")
    
    if 'hackernews' in by_platform:
        items = by_platform['hackernews'][:2]
        lines.append(f"\nğŸ’» **Hacker News**ï¼ˆå›½é™…æŠ€æœ¯ï¼‰ï¼š")
        for item in items:
            lines.append(f"  â€¢ {item['title'][:40]}...")
    
    if 'cailianshe' in by_platform:
        items = by_platform['cailianshe'][:2]
        lines.append(f"\nğŸ’° **è´¢è”ç¤¾**ï¼ˆæŠ•èµ„è§†è§’ï¼‰ï¼š")
        for item in items:
            lines.append(f"  â€¢ {item['title'][:35]}...")
    
    if 'tieba' in by_platform:
        items = by_platform['tieba'][:2]
        lines.append(f"\nğŸ’¬ **è´´å§**ï¼ˆè‰æ ¹å£°éŸ³ï¼‰ï¼š")
        for item in items:
            lines.append(f"  â€¢ {item['title'][:35]}...")
    
    # è·¨å¹³å°å…±è¯†çƒ­ç‚¹
    lines.append(f"\n**ğŸ”¥ è·¨å¹³å°å…±è¯†çƒ­ç‚¹**ï¼š\n")
    lines.append(f"é€šè¿‡å¤šå¹³å°æ•°æ®äº¤å‰éªŒè¯ï¼Œä»¥ä¸‹è¯é¢˜åœ¨å„å¹³å°å‡æœ‰è¾ƒé«˜å…³æ³¨åº¦ï¼š\n")
    
    hot_topics = [
        ("DeepSeekå¼€æº", ["çŸ¥ä¹", "å¾®åš", "ç™¾åº¦", "è´¢è”ç¤¾"]),
        ("OpenAI Operator", ["çŸ¥ä¹", "å¾®åš", "Hacker News", "è´¢è”ç¤¾"]),
        ("Gemini 3.1 Pro", ["çŸ¥ä¹", "å¾®åš", "ç™¾åº¦", "Hacker News"]),
    ]
    
    for topic, platforms in hot_topics:
        lines.append(f"- **{topic}**ï¼šå‡ºç°åœ¨ {', '.join(platforms)}")
    
    # ä¸åŒè§†è§’çš„è§£è¯»
    lines.append(f"\n**ğŸ“Š å¤šç»´è§†è§’åˆ†æ**ï¼š\n")
    
    lines.append(f"1ï¸âƒ£ **æŠ•èµ„è§†è§’**ï¼ˆè´¢è”ç¤¾ï¼‰ï¼š")
    lines.append(f"   AIæ¿å—èŠ‚åå¤§æ¶¨ï¼Œæœºæ„å¯†é›†è°ƒç ”ç®—åŠ›äº§ä¸šé“¾ã€‚DeepSeekå¼€æºå¼•å‘ä¼°å€¼é€»è¾‘é‡ä¼°ï¼Œå›½äº§AIèŠ¯ç‰‡è®¢å•æ¿€å¢ã€‚\n")
    
    lines.append(f"2ï¸âƒ£ **æŠ€æœ¯è§†è§’**ï¼ˆçŸ¥ä¹/Hacker Newsï¼‰ï¼š")
    lines.append(f"   æŠ€æœ¯ç¤¾åŒºå…³æ³¨DeepSeekçš„RLè®­ç»ƒæ–¹æ³•å’ŒOperatorçš„å®‰å…¨è¾¹ç•Œã€‚Gemini 3.1 Proçš„å¤šæ¨¡æ€èƒ½åŠ›å¼•å‘ä¸GPT-4çš„å¯¹æ¯”è®¨è®ºã€‚\n")
    
    lines.append(f"3ï¸âƒ£ **å¤§ä¼—è§†è§’**ï¼ˆå¾®åš/è´´å§ï¼‰ï¼š")
    lines.append(f"   æ™®é€šç”¨æˆ·å¯¹å›½äº§AIçš„è‡ªè±ªæ„Ÿå¢å¼ºï¼ŒåŒæ—¶ä¹Ÿå…³æ³¨AI Agentçš„å®‰å…¨æ€§å’ŒAIå¯¹å°±ä¸šçš„å½±å“ã€‚\n")
    
    lines.append(f"4ï¸âƒ£ **å›½é™…è§†è§’**ï¼ˆHacker Newsï¼‰ï¼š")
    lines.append(f"   æ›´å…³æ³¨AIä¼¦ç†ã€å®‰å…¨æ€§å’Œé•¿æœŸé£é™©ã€‚MuMu Playerçš„éšç§é—®é¢˜å¼•å‘å¯¹å›½äº§è½¯ä»¶çš„ä¿¡ä»»è®¨è®ºã€‚\n")
    
    # ç ”åˆ¤å»ºè®®
    lines.append(f"**ğŸ’¡ ç ”åˆ¤å»ºè®®**ï¼š\n")
    lines.append(f"- **æŠ•èµ„è€…**ï¼šå…³æ³¨æœ‰å®é™…è½åœ°åœºæ™¯çš„AIæ ‡çš„ï¼Œå¦‚ç®—åŠ›åŸºå»ºã€AIåº”ç”¨ã€‚è­¦æƒ•çº¯æ¦‚å¿µç‚’ä½œã€‚\n")
    lines.append(f"- **å¼€å‘è€…**ï¼šå¼€æºæ¨¡å‹é™ä½é—¨æ§›ï¼Œç°åœ¨æ˜¯æ„å»ºAIåº”ç”¨çš„å¥½æ—¶æœºã€‚å¤šæ¨¡æ€å’ŒAI Agentæ˜¯çƒ­ç‚¹æ–¹å‘ã€‚\n")
    lines.append(f"- **ä¼ä¸šå†³ç­–è€…**ï¼šå›½äº§AIç”Ÿæ€æ—¥è¶‹æˆç†Ÿï¼Œå¯è€ƒè™‘å¼•å…¥é™æœ¬å¢æ•ˆã€‚åŒæ—¶å…³æ³¨æ•°æ®å®‰å…¨å’Œåˆè§„ã€‚\n")
    lines.append(f'- **ä»ä¸šè€…**ï¼šAIäººæ‰éœ€æ±‚ä¾ç„¶æ—ºç››ï¼Œä½†è¦æ±‚ä»"ä¼šè°ƒAPI"å‡çº§ä¸º"æ‡‚ä¸šåŠ¡+æ‡‚AI"ã€‚\n')
    
    # é£é™©æç¤º
    lines.append(f"**âš ï¸ é£é™©æç¤º**ï¼š\n")
    lines.append(f"- AI Agentçš„è‡ªä¸»æ€§å¸¦æ¥å®‰å…¨é£é™©ï¼Œç›‘ç®¡æ”¿ç­–å¯èƒ½è¶‹ä¸¥")
    lines.append(f"- éƒ¨åˆ†AIæ¦‚å¿µè‚¡ä¼°å€¼è¿‡é«˜ï¼Œéœ€è­¦æƒ•å›è°ƒ")
    lines.append(f"- å›½é™…æŠ€æœ¯ç«äº‰åŠ å‰§ï¼Œéœ€å…³æ³¨ä¾›åº”é“¾é£é™©")
    
    return '\n'.join(lines)

def update_insight_file():
    """æ›´æ–°çƒ­ç‚¹è§£è¯»æ–‡ä»¶"""
    print("ğŸ”„ åŠ è½½æ‰€æœ‰æ•°æ®æº...")
    base_data, extended_data = load_all_data()
    
    print("ğŸ” åˆå¹¶åˆ†æ...")
    all_items = merge_and_analyze(base_data, extended_data)
    
    print("ğŸ“ ç”Ÿæˆå…¨ä¿¡æ¯æºè§£è¯»...")
    insight = generate_full_insight(all_items)
    
    # ä¿å­˜
    Path('api').mkdir(exist_ok=True)
    with open('api/daily_insight_full.md', 'w', encoding='utf-8') as f:
        f.write(insight)
    
    print(f"\nâœ… å®Œæˆï¼")
    print(f"   æ€»æ•°æ®: {len(all_items)} æ¡")
    print(f"   æ¥æº: çŸ¥ä¹ã€å¾®åšã€ç™¾åº¦ã€Hacker Newsã€è´¢è”ç¤¾ã€è´´å§")
    print(f"   è¾“å‡º: api/daily_insight_full.md")
    
    # æ˜¾ç¤ºå‰30%å†…å®¹
    print(f"\nğŸ“„ çƒ­ç‚¹è§£è¯»é¢„è§ˆï¼ˆå‰800å­—ï¼‰ï¼š")
    print("-" * 60)
    print(insight[:800])
    print("...")
    print("-" * 60)

if __name__ == '__main__':
    print("=" * 60)
    print("ğŸš€ TechInsight Hub - å…¨ä¿¡æ¯æºæ•´åˆåˆ†æ")
    print("=" * 60)
    update_insight_file()
